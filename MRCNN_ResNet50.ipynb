{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T09:41:48.946743Z",
     "start_time": "2020-08-06T09:41:45.978941Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:36:01.118711Z",
     "start_time": "2020-07-29T13:36:00.940711Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(os.getcwd()+'\\\\images')\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(os.getcwd()+'\\\\images\\\\cropped')\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.getcwd()+'\\\\images\\\\cropped\\\\class_1')\n",
    "    os.makedirs(os.getcwd()+'\\\\images\\\\cropped\\\\class_2')\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:53:28.211962Z",
     "start_time": "2020-07-30T07:53:28.207963Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_video_path = os.getcwd()+'\\\\videos_validation\\\\'\n",
    "img_path = os.getcwd()+'\\\\images\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:36:01.130717Z",
     "start_time": "2020-07-29T13:36:01.125713Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# vidcap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# def getFrame(sec):\n",
    "#     vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "#     hasFrames,image = vidcap.read()\n",
    "#     if hasFrames:\n",
    "#         cv2.imwrite(img_path + str(count-1)+\".jpg\", image)     # save frame as JPG file\n",
    "#     return hasFrames\n",
    "# sec = 0\n",
    "# frameRate = 10 #//it will capture image in each 0.5 second\n",
    "# count=1\n",
    "# success = getFrame(sec)\n",
    "# while success:\n",
    "#     count = count + 1\n",
    "#     sec = sec + frameRate\n",
    "#     sec = round(sec, 2)\n",
    "#     success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:36:01.141717Z",
     "start_time": "2020-07-29T13:36:01.132715Z"
    }
   },
   "outputs": [],
   "source": [
    "def vid_to_frames(path = None, vid_name = None, frate_sec = 30):\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "\n",
    "    img_path = os.getcwd()+'\\\\images\\\\'\n",
    "\n",
    "    def getFrame(sec):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if hasFrames:\n",
    "            cv2.imwrite(img_path + str(count-1)+ '_' + vid_name[:-4] + \".jpg\", image)     # save frame as JPG file\n",
    "        return hasFrames\n",
    "    sec = 0\n",
    "    frameRate = frate_sec\n",
    "    count=1\n",
    "    success = getFrame(sec)\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:36:56.188706Z",
     "start_time": "2020-07-29T13:36:01.143715Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in tqdm(os.listdir(valid_video_path)):\n",
    "    vid_to_frames(valid_video_path + i, i, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:45:05.743064Z",
     "start_time": "2020-06-10T13:45:05.735063Z"
    }
   },
   "source": [
    "## Load R-CNN model (COCO, resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:53:29.668513Z",
     "start_time": "2020-07-30T07:53:29.661607Z"
    },
    "code_folding": [
     5
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting prediction bbox, classes, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:53:30.978604Z",
     "start_time": "2020-07-30T07:53:30.968605Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold, device):\n",
    "    img = Image.open(img_path) # Load the image\n",
    "    transform = transforms.Compose([transforms.ToTensor()]) # Defing PyTorch Transform\n",
    "    img = transform(img).to(device) # Apply the transform to the image\n",
    "    pred = model([img]) # Pass the image to the model\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].cpu().numpy())] # Get the Prediction Score\n",
    "    pred_boxes = [[i[0], i[1], i[2], i[3]] for i in list(pred[0]['boxes'].cpu().detach().numpy())] # Bounding boxes\n",
    "    pred_score = list(pred[0]['scores'].cpu().detach().numpy())\n",
    "    pred_mask = list(pred[0]['masks'].cpu().detach().numpy()) #MASK RCNN\n",
    "\n",
    "#     print(pred_boxes, pred_class, pred_score, pred_mask)\n",
    "#     print('^'*20)\n",
    "    \n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1] # Get list of index with score greater than threshold.\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    pred_score = pred_score[:pred_t+1]\n",
    "    pred_mask = pred_mask[:pred_t+1] #MASK RCNN\n",
    "    \n",
    "    return pred_boxes, pred_class, pred_score, pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T09:41:59.285054Z",
     "start_time": "2020-08-06T09:41:59.280067Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T09:41:59.654558Z",
     "start_time": "2020-08-06T09:41:59.460524Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(os.getcwd() + '/models/' + 'MRCNN.pt', map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:53:33.903689Z",
     "start_time": "2020-07-30T07:53:33.896684Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask(a,b,c,d, mask_param = 50):\n",
    "    if x != 'cropped':\n",
    "        img = Image.open(img_path + x)\n",
    "        suf = 0\n",
    "        idx = 0\n",
    "        \n",
    "        for per, box, msk in zip(b, a, d):\n",
    "            if per == 'person':\n",
    "\n",
    "                mm = (msk.squeeze() * 255).astype(np.uint8)\n",
    "                mm[mm<mask_param] = 0 #regulates area of the mask based on sharpness\n",
    "                mm[mm>0] = 255 #full white for all non-null mask pixels\n",
    "                mm = Image.fromarray(mm)\n",
    "                mm = ImageOps.invert(mm)\n",
    "\n",
    "                to_save = Image.composite(mm, img, mm)\n",
    "                to_save = to_save.crop(box=box)\n",
    "                \n",
    "                to_save.save(img_path + 'cropped\\\\class_1\\\\' + x + '_' + str(idx) + '_' + str(suf) + '.jpg')\n",
    "                \n",
    "                suf += 1\n",
    "                idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T07:55:53.713834Z",
     "start_time": "2020-07-30T07:53:37.041934Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/20 [00:00<?, ?it/s]C:\\Users\\glebs\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "100%|██████████████████████████████████████████| 20/20 [02:16<00:00,  6.83s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "excl_list = []\n",
    "l = 3\n",
    "\n",
    "\n",
    "for x in tqdm(os.listdir(img_path)[:20]):\n",
    "    a, b, c, d = [0], [0], [0], [0]\n",
    "    try:\n",
    "        a, b, c, d = get_prediction(img_path+x, 0.90, device)\n",
    "        mask(a,b,c,d, mask_param = 50)\n",
    "    except:\n",
    "        print(x, ' _'*20)\n",
    "        excl_list.append(x)\n",
    "#     results.append([a,b,c,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:47:12.284178Z",
     "start_time": "2020-07-29T06:46:55.411113Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, x in enumerate(os.listdir(img_path)):\n",
    "    if x != 'cropped':\n",
    "        img = Image.open(img_path + x)\n",
    "        suf = 0\n",
    "        for per, box, msk in zip(results[idx][1], results[idx][0], results[idx][3]):\n",
    "            if per == 'person':\n",
    "                \n",
    "                to_save = img.crop(box=box)\n",
    "                to_save.save(img_path + 'cropped\\\\class_2\\\\' + str(idx) + '_' + str(suf) + '.jpg')\n",
    "                suf += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:56:59.199860Z",
     "start_time": "2020-06-10T13:56:59.187884Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:49:30.063858Z",
     "start_time": "2020-07-27T16:49:29.879225Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rand_img = random.choice(os.listdir(img_path))\n",
    "# sers = pd.Series(os.listdir(img_path))\n",
    "# idx = sers[sers == rand_img].index.values[0]\n",
    "\n",
    "# img = np.array(Image.open(img_path+rand_img))\n",
    "\n",
    "# for per, box in zip(results[idx][1], results[idx][0]):\n",
    "#     if per == 'person':\n",
    "#         img = cv2.rectangle(img, (box[0], box[1]), ((box[2], box[3])), (0,0,255), 10)\n",
    "\n",
    "# plt.figure(figsize=(7,7))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T18:52:14.994677Z",
     "start_time": "2020-06-22T18:52:14.924659Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model, 'C:\\\\Users\\\\Gleb\\\\Documents\\\\Data science\\\\PROJECTS\\\\P1_object_detection\\\\Video_learning\\\\box_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:06:43.561426Z",
     "start_time": "2020-07-12T17:06:43.557430Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(img_path).intersection(excl_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create images for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:11:59.419411Z",
     "start_time": "2020-07-27T16:11:59.414401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# img=Image.open(img_path+rand_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T16:12:40.004685Z",
     "start_time": "2020-07-27T16:12:39.509158Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(os.getcwd()+'\\\\images\\\\cropped')\n",
    "except:\n",
    "    None\n",
    "\n",
    "try:\n",
    "    os.mkdir(os.getcwd()+'\\\\images\\\\cropped\\\\')\n",
    "    os.mkdir(os.getcwd()+'\\\\images\\\\cropped\\\\class_1')\n",
    "except:\n",
    "    None\n",
    "\n",
    "for idx, x in enumerate(os.listdir(img_path)):\n",
    "    if x != 'cropped':\n",
    "        img = Image.open(img_path + x)\n",
    "        suf = 0\n",
    "        for per, box in zip(results[idx][1], results[idx][0]):\n",
    "            if per == 'person':\n",
    "                to_save = img.crop(box=box)\n",
    "                to_save.save(img_path + 'cropped\\\\class_1\\\\' + str(idx) + '_' + str(suf) + '.jpg')\n",
    "                suf += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:12.072954Z",
     "start_time": "2020-07-27T18:29:12.057952Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:12.557100Z",
     "start_time": "2020-07-27T18:29:12.538096Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for testidation\n",
    "data_transforms = {\n",
    "    'cropped': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "#         transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = os.getcwd()+'\\\\images\\\\'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['cropped']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                             shuffle=shuffle, num_workers=4)\n",
    "              for x in ['cropped']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['cropped']}\n",
    "class_names = image_datasets['cropped'].classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random image show (from dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:15.345996Z",
     "start_time": "2020-07-27T18:29:13.994698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['cropped']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Loading classification model weights (ResNet 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:17.038345Z",
     "start_time": "2020-07-27T18:29:17.035345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loaded_model = models.resnet50(pretrained=True)\n",
    "# num_ftrs = loaded_model.fc.in_features\n",
    "# # Here the size of each output sample is set to 2.\n",
    "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "# loaded_model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:17.271028Z",
     "start_time": "2020-07-27T18:29:17.258025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Path_model_wts = 'C:/Users/gleb/Documents/Data science/PROJECTS/P1_object_detection/model1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:17.441780Z",
     "start_time": "2020-07-27T18:29:17.433779Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Path_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:17.877212Z",
     "start_time": "2020-07-27T18:29:17.650500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load('C:/Users/gleb/Documents/Data science/PROJECTS/P1_object_detection/Video_learning/predict_model.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:20.544250Z",
     "start_time": "2020-07-27T18:29:20.138374Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loaded_model.load_state_dict(torch.load(Path_model_wts))\n",
    "loaded_model = torch.load('C:/Users/gleb/Documents/Data science/PROJECTS/P1_object_detection/model_full.pt')\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:29:21.669517Z",
     "start_time": "2020-07-27T18:29:21.667517Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.save(loaded_model, 'C:\\\\Users\\\\Gleb\\\\Documents\\\\Data science\\\\PROJECTS\\\\P1_object_detection\\\\Video_learning\\\\predict_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Visualization of results (probs + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:30:54.003044Z",
     "start_time": "2020-07-27T18:30:53.987040Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "def visualize_model_cpu(model, data_set = 'test', num_images=6):\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[data_set]):\n",
    "            inputs = inputs.to(device)#.to('cpu')\n",
    "            labels = labels.to(device)#.to('cpu')\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            smth, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            title = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            all_preds.append(preds.cpu().numpy()[0])\n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('Gleb: {:.2f}, Katya: {:.2f}'.format(title.cpu().numpy()[0][0], title.cpu().numpy()[0][1]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "#                     model.train(mode=was_training)\n",
    "                    return\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:30:44.153517Z",
     "start_time": "2020-07-27T18:30:42.020040Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_model_cpu(loaded_model, 'cropped', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T18:52:22.256708Z",
     "start_time": "2020-06-22T18:52:22.250704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:38:47.484416Z",
     "start_time": "2020-07-27T18:38:47.194873Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'C:\\\\Users\\\\Gleb\\\\Documents\\\\Data science\\\\PROJECTS\\\\P1_object_detection\\\\Video_learning\\\\MRCNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T18:38:40.223508Z",
     "start_time": "2020-07-27T18:38:40.203210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:42:56.436364Z",
     "start_time": "2020-07-29T13:42:27.301347Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... \n",
      "Warning: 4 possible package resolutions (only showing differing packages):\n",
      "  - defaults/noarch::path.py-12.0.2-py_0, defaults/win-64::astroid-2.4.2-py37_0, defaults/win-64::lazy-object-proxy-1.4.3-py37he774522_0, defaults/win-64::path-14.0.1-py37_0, defaults/win-64::pylint-2.5.3-py37_0, defaults/win-64::wrapt-1.11.2-py37he774522_0\n",
      "  - defaults/noarch::path.py-12.4.0-0, defaults/win-64::astroid-2.4.2-py37_0, defaults/win-64::lazy-object-proxy-1.4.3-py37he774522_0, defaults/win-64::path-13.1.0-py37_0, defaults/win-64::pylint-2.5.3-py37_0, defaults/win-64::wrapt-1.11.2-py37he774522_0\n",
      "  - defaults/noarch::path.py-12.0.2-py_0, defaults/win-64::astroid-2.3.3-py37_0, defaults/win-64::lazy-object-proxy-1.5.0-py37he774522_0, defaults/win-64::path-14.0.1-py37_0, defaults/win-64::pylint-2.4.4-py37_0, defaults/win-64::wrapt-1.12.1-py37he774522_1\n",
      "  - defaults/noarch::path.py-12.4.0-0, defaults/win-64::astroid-2.3.3-py37_0, defaults/win-64::lazy-object-proxy-1.5.0-py37he774522_0, defaults/win-64::path-13.1.0-py37_0, defaults/win-64::pylint-2.4.4-py37_0, defaults/win-64::wrapt-1.12.1-py37he774522_1done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\glebs\\Anaconda3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2020.07  |           py37_0           6 KB\n",
      "    ipykernel-5.3.3            |   py37h5ca1d4c_0         182 KB\n",
      "    lazy-object-proxy-1.4.3    |   py37he774522_0          30 KB\n",
      "    lz4-c-1.9.2                |       h62dcd97_1         230 KB\n",
      "    pandas-datareader-0.9.0    |             py_0          72 KB\n",
      "    zstd-1.4.5                 |       h04227a9_0         456 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         976 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  typed-ast          pkgs/main/win-64::typed-ast-1.4.1-py37he774522_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  hypothesis-5.18.3-py_0\n",
      "  pytest-arraydiff-0.3-py37h39e3cac_0\n",
      "  pytest-astropy-0.8.0-py_0\n",
      "  pytest-astropy-header-0.1.2-py_0\n",
      "  pytest-doctestplus-0.7.0-py_0\n",
      "  pytest-openfiles-0.5.0-py_0\n",
      "  pytest-remotedata-0.3.2-py37_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  _anaconda_depends                          2020.02-py37_0 --> 2020.07-py37_0\n",
      "  astroid                                      2.3.3-py37_0 --> 2.4.2-py37_0\n",
      "  ipykernel                            5.3.2-py37h5ca1d4c_0 --> 5.3.3-py37h5ca1d4c_0\n",
      "  lz4-c                                    1.9.2-h62dcd97_0 --> 1.9.2-h62dcd97_1\n",
      "  pandas-datareader                              0.8.1-py_0 --> 0.9.0-py_0\n",
      "  pylint                                       2.4.4-py37_0 --> 2.5.3-py37_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  lazy-object-proxy                    1.5.0-py37he774522_0 --> 1.4.3-py37he774522_0\n",
      "  wrapt                               1.12.1-py37he774522_1 --> 1.11.2-py37he774522_0\n",
      "  zstd                                     1.4.5-ha9fde0e_0 --> 1.4.5-h04227a9_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "lz4-c-1.9.2          | 230 KB    |            |   0% \n",
      "lz4-c-1.9.2          | 230 KB    | ########## | 100% \n",
      "\n",
      "zstd-1.4.5           | 456 KB    |            |   0% \n",
      "zstd-1.4.5           | 456 KB    | ########## | 100% \n",
      "\n",
      "_anaconda_depends-20 | 6 KB      |            |   0% \n",
      "_anaconda_depends-20 | 6 KB      | ########## | 100% \n",
      "\n",
      "ipykernel-5.3.3      | 182 KB    |            |   0% \n",
      "ipykernel-5.3.3      | 182 KB    | ########## | 100% \n",
      "\n",
      "lazy-object-proxy-1. | 30 KB     |            |   0% \n",
      "lazy-object-proxy-1. | 30 KB     | ########## | 100% \n",
      "\n",
      "pandas-datareader-0. | 72 KB     |            |   0% \n",
      "pandas-datareader-0. | 72 KB     | ##2        |  22% \n",
      "pandas-datareader-0. | 72 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:44:31.867653Z",
     "start_time": "2020-07-29T13:44:05.483381Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version           Latest    Type\n",
      "---------------------- ----------------- --------- -----\n",
      "asn1crypto             1.3.0             1.4.0     wheel\n",
      "bitarray               1.4.0             1.4.2     sdist\n",
      "boto3                  1.14.12           1.14.30   wheel\n",
      "botocore               1.17.12           1.17.30   wheel\n",
      "branca                 0.4.0             0.4.1     wheel\n",
      "cffi                   1.14.0            1.14.1    wheel\n",
      "cryptography           2.9.2             3.0       wheel\n",
      "dash                   1.9.0             1.14.0    sdist\n",
      "dash-core-components   1.8.0             1.10.2    sdist\n",
      "dash-daq               0.3.3             0.5.0     sdist\n",
      "dash-html-components   1.0.2             1.0.3     sdist\n",
      "dash-renderer          1.2.4             1.6.0     sdist\n",
      "dash-table             4.6.0             4.9.0     sdist\n",
      "dask                   2.20.0            2.21.0    wheel\n",
      "distributed            2.20.0            2.21.0    wheel\n",
      "docutils               0.15.2            0.16      wheel\n",
      "dtale                  1.7.5             1.11.0    wheel\n",
      "Flask-Compress         1.4.0             1.5.0     sdist\n",
      "folium                 0.10.1            0.11.0    wheel\n",
      "gensim                 3.8.0             3.8.3     wheel\n",
      "google-api-core        1.20.0            1.22.0    wheel\n",
      "google-auth            1.18.0            1.20.0    wheel\n",
      "google-cloud-storage   1.28.1            1.30.0    wheel\n",
      "google-resumable-media 0.5.1             0.7.0     wheel\n",
      "graphviz               0.14              0.14.1    wheel\n",
      "h5py                   2.8.0             2.10.0    wheel\n",
      "hiplot                 0.1.15            0.1.18    wheel\n",
      "ipykernel              5.3.3             5.3.4     wheel\n",
      "isort                  4.3.21            5.2.1     wheel\n",
      "jedi                   0.17.1            0.17.2    wheel\n",
      "jupyter-latex-envs     1.4.4             1.4.6     sdist\n",
      "jupyterlab             2.1.5             2.2.2     wheel\n",
      "lazy-object-proxy      1.4.3             1.5.1     wheel\n",
      "lz4                    3.0.2             3.1.0     wheel\n",
      "macholib               1.11              1.14      wheel\n",
      "matplotlib             3.2.2             3.3.0     wheel\n",
      "numpy                  1.18.5            1.19.1    wheel\n",
      "opencv-python          4.2.0.34          4.3.0.36  wheel\n",
      "pandas                 1.0.5             1.1.0     wheel\n",
      "pandas-profiling       1.4.1             2.8.0     wheel\n",
      "parso                  0.7.0             0.7.1     wheel\n",
      "path                   14.0.1            15.0.0    wheel\n",
      "path.py                12.0.2            12.5.0    wheel\n",
      "pip                    20.1.1            20.2      wheel\n",
      "plotly                 4.5.1             4.9.0     wheel\n",
      "psutil                 5.7.0             5.7.2     wheel\n",
      "pycryptodome           3.8.2             3.9.8     wheel\n",
      "pyforest               1.0.1             1.0.3     sdist\n",
      "pyodbc                 4.0.0-unsupported 4.0.30    wheel\n",
      "pytest                 5.4.3             6.0.0     wheel\n",
      "pywin32                227               228       wheel\n",
      "regex                  2020.6.8          2020.7.14 wheel\n",
      "ruamel-yaml            0.15.87           0.16.10   wheel\n",
      "scikit-image           0.16.2            0.17.2    wheel\n",
      "scipy                  1.5.0             1.5.2     wheel\n",
      "spyder-kernels         1.9.2             1.9.3     wheel\n",
      "tables                 3.4.4             3.6.1     wheel\n",
      "tblib                  1.6.0             1.7.0     wheel\n",
      "tqdm                   4.47.0            4.48.0    wheel\n",
      "ujson                  1.35              3.0.0     wheel\n",
      "umap-learn             0.3.10            0.4.6     sdist\n",
      "urllib3                1.25.9            1.25.10   wheel\n",
      "wrapt                  1.11.2            1.12.1    sdist\n",
      "xgboost                0.90              1.1.1     wheel\n",
      "xlwings                0.19.5            0.20.0    sdist\n",
      "zope.interface         4.7.1             5.1.0     wheel\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list --outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
